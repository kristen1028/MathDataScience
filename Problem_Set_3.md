"""
Problem Set 3.ipynb

This script is auto-generated by Colaboratory. It is used for plotting tensor images and visualizing 
convolutional features of an AlexNet model.
The original file can be found at:
    https://colab.research.google.com/drive/1uZIU9h_MgpIvxjGjDMv6yr80vSOS32Ph
"""

# Import necessary libraries
```python
import matplotlib.pyplot as plt
import torch
from torchvision import datasets, transforms, models
import os
import pandas as pd
from PIL import Image
import requests
import torch.nn.functional as F
```
This code block prepares the environment by importing tools necessary for tasks like data visualization, deep learning, data manipulation, image processing, and web requests.

# Function to plot tensor images
```python
def plot(x, title=None):

    """Plots a tensor image.
    
    Args:
    - x (torch.Tensor): The image tensor.
    - title (str, optional): Title for the plot.
    """
    # Convert tensor to numpy array
    x_np = x.cpu().numpy()

    # Transpose tensor from (Channels, Height, Width) to (Height, Width, Channels) if necessary
    if x_np.shape[0] in [1, 3]:
        x_np = x_np.transpose(1, 2, 0)

    # If image is grayscale, squeeze out the color channel dimension
    if x_np.shape[2] == 1:
        x_np = x_np.squeeze(2)

    # Clip pixel values to [0, 1]
    x_np = x_np.clip(0, 1)

    # Create a new figure and axis for plotting
    fig, ax = plt.subplots()
    if len(x_np.shape) == 2:  # Grayscale image
        ax.imshow(x_np, cmap='gray')
    else:
        ax.imshow(x_np)
    plt.title(title)
    ax.axis('off')
    fig.set_size_inches(10, 10)
    plt.show()
```
This code creates a visual display of the input image tensor, either in grayscale or RGB format, with an optional title. The size of the displayed image is set to 10x10 inches.

# Download and extract the dataset
```python
!wget https://gist.githubusercontent.com/JosephKJ/94c7728ed1a8e0cd87fe6a029769cde1/raw/403325f5110cb0f3099734c5edb9f457539c77e9/Oxford-102_Flower_dataset_labels.txt
!wget https://s3.amazonaws.com/content.udacity-data.com/courses/nd188/flower_data.zip
!unzip 'flower_data.zip'
```
This code downloads the dataset to be used. 

# Define the dataset directory and normalization values
```python
data_dir = '/content/flower_data/'
mean = [0.485, 0.456, 0.406]
std = [0.229, 0.224, 0.225]
```
The code block specifies a directory path to flower data and sets normalization parameters (mean and standard deviation) for image processing, which are commonly used with pretrained deep learning models.

# Define the image transformations for the dataset
```python
data_transform = transforms.Compose([
    transforms.RandomResizedCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean, std)
])
```
The code block defines an image transformation pipeline that randomly crops the image to a fixed size, converts it into a tensor format, and then normalizes its pixel values using the provided mean and standard deviation. This transformed data is then ready to be fed into a deep learning model.

# Load dataset using torchvision's ImageFolder and get the dataset labels
```python
dataset = datasets.ImageFolder(os.path.join(data_dir, 'train'), data_transform)
dataset_labels = pd.read_csv('Oxford-102_Flower_dataset_labels.txt', header=None)[0].str.replace("'", "").str.strip()
```
This code block performs two tasks. The first task it performs is making sure that when you retrieve an image from this dataset, it will be automatically cropped to a size of 224x224, converted to a tensor, and normalized using the specified 'mean' and 'std'. The second task it performs is it reads a text file named 'Oxford-102_Flower_dataset_labels.txt' to extract the labels for the dataset. 

# Load dataset into a DataLoader for batching
```python
dataloader = torch.utils.data.DataLoader(dataset, batch_size=len(dataset), shuffle=False)
```
This code sets up a DataLoader that will provide the entire dataset in a single batch without any shuffling.

# Extract a batch of images and labels
```python
images, labels = next(iter(dataloader))

print(f"Images tensor shape: {images.shape}")
print(f"Labels tensor shape: {labels.shape}")
```
This code retrieves all the images and labels from the dataset using the DataLoader and then prints out the shapes of the retrieved images and labels tensors to provide insights into their dimensions.

# Plot the 50th image in the batch
```python
i = 50
plot(images[i], dataset_labels[i])
```
![image](https://github.com/kristen1028/MathDataScience/assets/143013164/a82b0347-656a-43f8-b442-57215ea2f9bb)

This code selects the 51st image (0-indexed, so index 50) from the dataset and displays it with its corresponding label as the title.

# Prepare the device for computations
```python
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
```
This code is setting up the device variable to specify whether to run subsequent PyTorch operations on the GPU (if available) or the CPU.

# Load pretrained AlexNet model
```python
alexnet = models.alexnet(pretrained=True).to(device)
labels = {int(key): value for (key, value) in requests.get('https://s3.amazonaws.com/mlpipes/pytorch-quick-start/labels.json').json().items()}
```
The code block loads a pre-trained AlexNet model, moves it to the desired device (GPU or CPU), and fetches the class labels that correspond to the output classes of the model.

# Image preprocessing for AlexNet model
```python
preprocess = transforms.Compose([
   transforms.Resize(256),
   transforms.CenterCrop(224),
   transforms.ToTensor(),
   transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])
```
The code block creates a preprocess pipeline using the transforms.Compose() function. This pipeline is designed to take an image, apply the defined transformations in sequence, and produce an output tensor that's ready to be fed into a model like AlexNet.

# Convert tensor image back to PIL format
```python
from torchvision.transforms import ToPILImage
to_pil = ToPILImage()
img = to_pil(images[i])
img_t = preprocess(img).unsqueeze_(0).to(device)
```
The code block takes the 'i'-th image tensor from the batch 'images', converts it to a PIL image, preprocesses it to make it suitable for a model, adds a batch dimension, and then sends it to the appropriate device (either GPU or CPU). The resulting tensor, 'img_t', is now ready to be input to a neural network model.

# Use the pre-trained AlexNet model to classify the image
```python
scores, class_idx = alexnet(img_t).max(1)
print('Predicted class:', labels[class_idx.item()])
```
The code block uses the 'alexnet' model to predict the class of the image represented by 'img_t', and then it prints out the human-readable name of the predicted class using the labels dictionary.

# Extract weights from different layers of the AlexNet model
```python
w0 = alexnet.features[0].weight.data
w1 = alexnet.features[3].weight.data
w2 = alexnet.features[6].weight.data
w3 = alexnet.features[8].weight.data
w4 = alexnet.features[10].weight.data
w5 = alexnet.classifier[1].weight.data
w6 = alexnet.classifier[4].weight.data
w7 = alexnet.classifier[6].weight.data
```
This code uses the AlexNet model to extract weights from the different layers. 

# Printing the shapes of img_t and w0 tensors
```python
img_t.shape, w0.shape
```
This code retrieves the shape of two tensors: 'img_t' and 'w0'. The '.shape' attribute returns the dimensions of a tensor in PyTorch. 

# Printing the shape of the img_t tensor
```python
img_t.shape
```
This code prints the shape of 'img_t'. 

# Printing the shape of the first image tensor in the batch
```python
img_t[0,:,:,:].shape
```
This code retrieves the shape of a subset of the img_t tensor. Specifically, it selects the first element (index 0) along the batch dimension (or the first dimension) and includes all the elements in the other dimensions.

# Function to normalize an image tensor to the range [0, 1]
```python
def scale(img):
    # Determine the maximum and minimum values of the image tensor
    max_value = img.max()
    min_value = img.min()
    # Normalize the image tensor
    normalized_array = (img - min_value) / (max_value - min_value)
    return normalized_array
```
This function ensures that the pixel values of the image tensor are in the [0, 1] range.

# Function to plot an image tensor
```python
def tensor_plot(img_t, index=0):
    # Convert the specified image tensor to a numpy array
    numpy_array = img_t[index,:,:,:].cpu().numpy()
    # Transpose the numpy array from (C, H, W) format to (H, W, C) format for visualization
    numpy_array_transposed = numpy_array.transpose(1, 2, 0)
    # Normalize the numpy array using the previously defined scale function
    numpy_array_transposed = scale(numpy_array_transposed)
    # Display the image using matplotlib
    plt.imshow(numpy_array_transposed)
    plt.show()
```
The function takes a tensor of images and an index, and it visualizes the specified image from the tensor.

# Visualize the specified image tensor using the tensor_plot function
```python
tensor_plot(img_t)
```
![image](https://github.com/kristen1028/MathDataScience/assets/143013164/60babb27-107e-4540-b75e-cbfe21bff901)

The function call displays the first image from the tensor 'img_t'.

# Printing the shape of the w0 tensor
```python
w0.shape
```

# Apply the convolutional operation using the w0 filter on the img_t tensor
```python
f0 = F.conv2d(img_t, w0, stride=4, padding=2)
```
'f0', is a tensor containing the feature maps (output) produced by convolving 'img_t' with the filters 'w0'. 

# Printing the shape of the resulting feature map
```python
f0.shape
```

# Displaying the first feature map of the first image in the batch
```python
i = 0
plt.imshow(f0[0,i,:,:].cpu().numpy())
```
![image](https://github.com/kristen1028/MathDataScience/assets/143013164/33a33f26-c61a-4c8e-9aae-8cd560ece574)

The code is visualizing the first feature map of the first image in the batch from the tensor 'f0'.

# A function to plot feature maps with overlayed filters
```python
def plot_feature_maps_with_filters(feature_maps, filters):
    """Plots feature maps with RGB filters overlayed at the lower-left corner.
    
    Args:
    - feature_maps (torch.Tensor): The feature maps tensor.
    - filters (torch.Tensor): The filter tensors.
    """
    # ... [rest of the function implementation] ...

plot_feature_maps_with_filters(f0, w0)
```
This code is meant to provide a visual representation of the relationship between convolutional filters and the feature maps they produce, making it easier to understand and interpret the effects of the filters on the original image.

```python
import torch
import matplotlib.pyplot as plt

def plot_feature_maps_with_filters(feature_maps, filters):
    # Remove batch dimension if it exists
    if feature_maps.dim() == 4:
        feature_maps = feature_maps.squeeze(0)

    # Normalize feature maps to [0, 1]
    feature_maps = (feature_maps - feature_maps.min()) / (feature_maps.max() - feature_maps.min())

    def add_filter_to_feature_map(filter_tensor, feature_map_tensor):
        # Ensure the feature map is 2D [H, W]
        if feature_map_tensor.dim() > 2:
            feature_map_tensor = feature_map_tensor.squeeze(0)

        # Convert grayscale feature map to RGB by repeating the single channel 3 times
        feature_map_rgb = feature_map_tensor.unsqueeze(0).repeat((3, 1, 1))

        # Normalize the filter to [0, 1]
        filter_tensor = (filter_tensor - filter_tensor.min()) / (filter_tensor.max() - filter_tensor.min())

        # Ensure the filter fits into the feature map
        min_dim = min(feature_map_tensor.shape)
        filter_size = min(filter_tensor.shape[-1], min_dim)

        # Crop the filter if needed
        filter_cropped = filter_tensor[:, :filter_size, :filter_size]

        # Overlay the RGB filter at the lower-left corner of the feature map
        feature_map_rgb[:, -filter_size:, :filter_size] = filter_cropped

        # Clip the values to be in the range [0, 1]
        feature_map_rgb = torch.clamp(feature_map_rgb, 0, 1)

        return feature_map_rgb

    # Plot montage of feature maps
    fig, axes = plt.subplots(8, 8, figsize=(15, 15))

    for ax, feature_map, filter_ in zip(axes.flat, feature_maps, filters):
        # Add RGB filter to grayscale feature map
        modified_feature_map = add_filter_to_feature_map(filter_, feature_map)

        # Plot modified feature map
        ax.imshow(modified_feature_map.permute(1, 2, 0).cpu().numpy(), interpolation='none')  # Added 'none' interpolation
        ax.axis('off')

    plt.show()
```
This function provides a visual way to understand the relationship between convolutional filters and the feature maps they produce. It's particularly useful to see how different filters emphasize or extract specific features from an image. 

# Printing the shape of feature maps tensor 'f0' and filters tensor 'w0'
```
f0.shape, w0.shape
```

# Using the function to visualize the feature maps with overlayed filters
```python
plot_feature_maps_with_filters(f0, w0)
```
![image](https://github.com/kristen1028/MathDataScience/assets/143013164/23af2a74-0fcf-4512-a8eb-72631a5748f6)

The code will produce a visualization where each feature map from f0 is displayed, and its corresponding filter from w0 is overlaid on its lower-left corner. This visualization helps in understanding how different filters emphasize or extract specific features from an image.
