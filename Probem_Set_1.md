# Importing necessary libraries and modules
# -*- coding: utf-8 -*-
"""
Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SFlf_ZjDVtHJbsu1z0Y40E8y4MzvkXZT
"""

# Importing required libraries
```python
import numpy as np
import matplotlib.pyplot as plt
import torch
from torchvision import datasets
from skimage.util import montage
!pip install wandb
import wandb as wb
from skimage.io import imread
```
In this code block, I am importing the libraries I need for this code to run, such as NumPy, Matplotlib, Torch, datatsets from Torchvision, montages from skimage.util, and Wandb.  

# Define functions for GPU operations and plotting
```python
def GPU(data):
    return torch.tensor(data, requires_grad=True, dtype=torch.float, device=torch.device('cuda'))

def GPU_data(data):
    return torch.tensor(data, requires_grad=False, dtype=torch.float, device=torch.device('cuda'))

def plot(x):
    """
    Plots an image represented by tensor 'x'.
    Args:
        x: Tensor representing an image.
    """
    if type(x) == torch.Tensor:
        x = x.cpu().detach().numpy()

    fig, ax = plt.subplots()
    im = ax.imshow(x, cmap='gray')
    ax.axis('off')
    fig.set_size_inches(7, 7)
    plt.show()

def montage_plot(x):
    """
    Plots a montage of images represented by the tensor 'x'.
    Args:
        x: Tensor representing a collection of images.
    """
    x = np.pad(x, pad_width=((0, 0), (1, 1), (1, 1)), mode='constant', constant_values=0)
    plot(montage(x))
```
"GPU(data)" inputs data and outputs a PyTorch tensor. The tensor is created with the input data, with the "requires_grad" attribute set to "True" indicating that gradients should be computed for this tensor. "GPU_dat(data)" also inputs data and outputs a PyTorch tensor. But,the "requires_grad" attribute is set to "False", which indicates that gradiants do not need to be computed for this tensor. Overall, this code block allows me to use GPU tensors, plot single images, and create montages of multiple images for visualization. 

# Load MNIST dataset
```python
train_set = datasets.MNIST('./data', train=True, download=True)
test_set = datasets.MNIST('./data', train=False, download=True)
```
The "train_set" line of code creates a training dataset object using the MNIST dataset. The "test_set" line of code creates a testing dataset object using the MNIST dataset. 

# Preprocess image data
```python
X = train_set.data.numpy()
X_test = test_set.data.numpy()
Y = train_set.targets.numpy()
Y_test = test_set.targets.numpy()

X = X[:, None, :, :] / 255
X_test = X_test[:, None, :, :] / 255
```
This code block preprocesses the MNIST training and testing data to extract the images and labels by converting them to NumPy arrays, adjusts the dimensions of the images to include a channel dimesion, and normalizes the pixel values. 

# Display the shape of X
```python
X.shape
```
This code expresses the shape of the array (X) in terms of dimension, and provides information about the number of elements along each axis of the array. 

# Display the shape of a subset of X
```python
X[0:25, 0, :, :].shape
```
This code selects the first 25 images. The first dimension will show the number of selected sample (25), and the second and third dimesnion will show the height and width of each selected image. 

# Plot a montage of images
```python
montage_plot(X[125:150, 0, :, :])
```
![image](https://github.com/kristen1028/MathDataScience/assets/143013164/d2d0dee9-a357-4512-b5c2-2453a1902ec9)
This line of code displays a montage of the first 25 images selected from the previous line of code. 

# Reshape image tensors
```python
X = X.reshape(X.shape[0], 784)
X_test = X_test.reshape(X_test.shape[0], 784)
```
This code block reshapes each image in the training and tetsing datasets to 784 columns. 

# Convert data to GPU tensors
```python
X = GPU_data(X)
Y = GPU_data(Y)
X_test = GPU_data(X_test)
Y_test = GPU_data(Y_test)
```
This code block is converting the NumPy arrays (X, Y, X_test, Y_test) into PyTorch tensors and putting them on a CUDA device. 

# Display the shape of X
```python
X.shape
```
This code expresses the shape of the array (X) in terms of dimension, and provides information about the number of elements along each axis of the array.

# Extract a subset of X
```python
x = X[:, 0:64]
```
This line of code creates a new array (x), by selected the first 64 columns for every row from the original array (X). 

# Transpose X
```python
X = X.T
```
This line of code transforms the original array (X) by effectively swapping the rows and columns. 

# Display the shape of X
```python
X.shape
```
This code expresses the shape of the array (X) in terms of dimension, and provides information about the number of elements along each axis of the array.

# Create a random model 'M' and perform matrix multiplication
```python
M = GPU(np.random.rand(10, 784))
```
This line of code generates a random array representing 10 samples with 784 features each, converts it to a PyTorch tensor, sets it up for gradient computation, and places it on a CUDA device, assigning the resulting tensor to the variable M.

# Set batch size
```python
batch_size = 64
```
This line of code sets the batch_size variable to 64, indicating that during training, the model will process and update its weights based on batches of 64 samples at a time.

# Extract a batch of image data
```python
x = X[:, 0:batch_size]
```
This line of code creates a new array (x) by selecting the first batch_size columns for every row from the original array (X). 

# Update the random model and perform matrix multiplication
```python
M = GPU(np.random.rand(10, 784))
y = M @ x
```
This code block generates a random matrix (M), places it on a GPU, and then performs matrix multiplication between "M" and "x", resulting in a new matrix (y). 

# Calculate accuracy based on model predictions
```python
y = torch.argmax(y, 0)
torch.sum((y == Y[0:batch_size])) / batch_size
```
This code block calculates the accuracy of a model's predictions (y) for the batch_size (64). It first finds the predicted class indices for each sample (argmax), compares these with the true class labels for the batch, and then computes the accuracy as the fraction of correct predictions in the batch.

# Train a random walk model to achieve at least 75% accuracy
```python
m_best = 0
acc_best = 0
for i in range(100000):
    step = 0.0000000001
    m_random = GPU_data(np.random.randn(10, 784))
    m = m_best + step * m_random

    y = m @ X

    y = torch.argmax(y, axis=0)

    acc = ((y == Y)).sum() / len(Y)

    if acc > acc_best:
        print(acc.item())
        m_best = m
        acc_best = acc
```
I reached 87.3% accuracy. This code block is updating a base model (m_best) using small random perturbations and selecting the model that achieves the highest accuracy on the given dataset (X and Y). The loop runs for 100,000 iterations. The step size for the perturbations is set to a very small value (0.0000000001). If the current accuracy is better than the best accuracy found so far, it is printed, and "M_best" and "accuracy_best" are updated with the new model and accuracy. 
